# LLM Provider Configuration
# Choose your provider: dashscope, openai, anthropic
LLM_PROVIDER=dashscope

# DashScope Configuration (Alibaba Cloud)
DASHSCOPE_API_KEY=your_dashscope_api_key_here
DASHSCOPE_MODEL_NAME=qwen3-max
# Optional: Custom base URL for DashScope API
# DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/api/v1

# OpenAI Configuration
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL_NAME=gpt-4o
# OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Configuration
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL_NAME=claude-3-5-sonnet-20241022
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# Model Parameters (applied to all providers)
# Temperature controls randomness: 0.0 = deterministic, 1.0 = creative
MODEL_TEMPERATURE=0.7

# Maximum tokens to generate (optional)
# MODEL_MAX_TOKENS=2048

# Top-p sampling (optional)
# MODEL_TOP_P=0.9

# Enable streaming responses (true/false)
MODEL_STREAM=true

# Enable thinking mode for supported models (QwQ, DeepSeek-R1, etc.)
# MODEL_ENABLE_THINKING=false

# Application Configuration
# Add other application-specific environment variables below
